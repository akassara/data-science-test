{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DreamQuark_challenge.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVi5D_zuOYn7"
      },
      "source": [
        "!pip install pytorch_tabnet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjzpEyIisrK6"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "import xgboost as xgb\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRDv7sn6k5aO"
      },
      "source": [
        "%cd  /content/drive/My Drive/Dreamquark_challenge"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAEord9dko0f"
      },
      "source": [
        "# Data preprocessing and feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gi2A1DTdbF9Y"
      },
      "source": [
        "requests_train = pd.read_csv('data/requests_train.csv')\n",
        "individuals_train = pd.read_csv('data/individuals_train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GS0QUqDMp8JY"
      },
      "source": [
        "First let's check the amount of missing values, we will focus for a first approach on the requests_train dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jo9bEozOs1mC"
      },
      "source": [
        "#Calculate the percentage of null values for each variable\n",
        "nullDist = requests_train.isnull().sum().reset_index()\n",
        "nullDist.columns=['column_name', 'null_Percentage']\n",
        "c = len(requests_train)\n",
        "for i,v in nullDist.null_Percentage.iteritems():\n",
        "    nullDist.null_Percentage[i]=(v*100)/c\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(25,10))\n",
        "nullDist.plot.bar(ax=ax)    \n",
        "ax.set_xlabel('Variable')\n",
        "ax.set_ylabel('percentage')\n",
        "\n",
        "#Save the plot in Output folder\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RHjlONPwaDs"
      },
      "source": [
        "print(requests_train.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppOChI1rxSsz"
      },
      "source": [
        "The categorical variable victim_of_violence_type as a very high rate of undefined values, let's see the correlation with the variable victim_of_violence, which is a binary variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjI2SS1ylpQq"
      },
      "source": [
        "no_violence_victim_df = requests_train.loc[requests_train['victim_of_violence']=='f']\n",
        "print('The values of victim_violence_type for non victims ', list(no_violence_victim_df['victim_of_violence_type'].unique()))\n",
        "violence_victim_df = requests_train.loc[requests_train['victim_of_violence']=='t']\n",
        "print('The values of victim_violence_type for  victims ', list(violence_victim_df['victim_of_violence_type'].unique()))\n",
        "print('number of nans for victims of violence',violence_victim_df['victim_of_violence_type'].isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeUzV9EC1iJg"
      },
      "source": [
        "Thus to encode this variable, we will assign a zero to all nan values that are not victims of violence and a different value for the nan values victims of violence type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6an-I2PqH34"
      },
      "source": [
        "def encode_victims_of_violence_type(df):\n",
        "  no_violence_victim_df = df.loc[df['victim_of_violence']=='f']\n",
        "  violence_victim_df = df.loc[df['victim_of_violence']=='t']\n",
        "  df['victim_of_violence_type'] = df['victim_of_violence_type'].astype(str)\n",
        "  encoder = LabelEncoder()\n",
        "  df['encoded_victim_of_violence_type'] = encoder.fit_transform(df['victim_of_violence_type'])\n",
        "  for i in no_violence_victim_df.index:\n",
        "    df['encoded_victim_of_violence_type'][i] = -1\n",
        "  for i in range(len(df)):\n",
        "    df['encoded_victim_of_violence_type'][i] += 1\n",
        "  df = df.drop(columns=['victim_of_violence_type'])\n",
        "  return df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXn2UuutqQm4"
      },
      "source": [
        "# Dataframe of categorical variables:\n",
        "categorical_val= list(requests_train.select_dtypes(include=[np.object]))\n",
        "categorical_val.remove('request_id')\n",
        "#we remove the date variable, we will deal with it later\n",
        "categorical_val.remove('answer_creation_date')\n",
        "categorical_val.remove('group_creation_date')\n",
        "categorical_val.remove('request_creation_date')\n",
        "categorical_val.remove('victim_of_violence_type')\n",
        "categorical_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meCIXFrYQgZB"
      },
      "source": [
        "# let' encode these categorical variables\n",
        "def encode_categorical_variables(df,columns):\n",
        "  for column in columns:\n",
        "    df[column] = df[column].astype(str)\n",
        "    encoder = LabelEncoder()\n",
        "    df[column] = encoder.fit_transform(df[column])\n",
        "    df.loc[df[column].isnull(),column] = -1\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PKYFuUDBbUH"
      },
      "source": [
        "# To encode the date variables we are going to follow a simple approach: keep the year and the month.\n",
        "def encode_date_variable(df,columns):\n",
        "  for column in columns:\n",
        "    df[column] = pd.to_datetime(df[column])\n",
        "    df[column+'_year'] = df[column].dt.year\n",
        "    df[column+'_month'] = df[column].dt.month\n",
        "    df = df.drop(columns = [column])\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AI-5p0M8vZZH"
      },
      "source": [
        "def preprocess(df,cat_columns,date_columns):\n",
        "  \"\"\" Transform dataframe into to encoded features and targets\n",
        "  \"\"\"\n",
        "  df = encode_victims_of_violence_type(df)\n",
        "  df = encode_categorical_variables(df,cat_columns)\n",
        "  df = encode_date_variable(df,date_columns)\n",
        "  features = list(df.columns)\n",
        "  features.remove('request_id')\n",
        "  features.remove('granted_number_of_nights')\n",
        "  X = df[features]\n",
        "  y = df[\"granted_number_of_nights\"]\n",
        "  return X,y\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymd5o42fwXou"
      },
      "source": [
        "cat_columns = categorical_val\n",
        "date_columns = ['answer_creation_date','group_creation_date','request_creation_date']\n",
        "X,y = preprocess(requests_train,cat_columns,date_columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fsRJxohZVyf"
      },
      "source": [
        "# Random Forrest Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "as1wlTwOVuSX"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9YoeNQJZT-L"
      },
      "source": [
        "# split between the train and the validation samples\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQOFCoHlak2Y"
      },
      "source": [
        "xgb_model = xgb.XGBClassifier(max_depth = 4,learning_rate = 0.01,n_estimators=10000)\n",
        "xgb_model.fit(X_train, y_train, sample_weight=10**y_train, eval_set=[(X_val, y_val)],eval_metric = 'mlogloss',early_stopping_rounds= 100,sample_weight_eval_set=[10**y_val])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09nnHDl8joFu"
      },
      "source": [
        "xgb_model.save_model('/content/drive/My Drive/Dreamquark_challenge/model_zoo/xgb_model.model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9qiLUG1zGnh"
      },
      "source": [
        "xgb.plot_importance(xgb_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrtSOKn4p2X9"
      },
      "source": [
        "## Inference on test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EenYfVIddSbV"
      },
      "source": [
        "# Define the test scorer\n",
        "def competition_scorer(y_true, y_pred):\n",
        "    return log_loss(y_true, y_pred, sample_weight=10**y_true)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzr7o5StdEfb"
      },
      "source": [
        "requests_test = pd.read_csv('data/requests_test.csv')\n",
        "X_test , y_test = preprocess(requests_test,cat_columns,date_columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IC8CKvyH0EIG"
      },
      "source": [
        "#retrieve saved model\n",
        "best_model = xgb.Booster()\n",
        "PATH = '/content/drive/My Drive/Dreamquark_challenge/model_zoo/xgb_model.model'\n",
        "best_model.load_model(PATH)\n",
        "print('The model has been loaded')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnvzSc0cr8bT"
      },
      "source": [
        "#run inference\n",
        "start = time.time()\n",
        "preds = best_model.predict(xgb.DMatrix(X_test))\n",
        "end = time.time()\n",
        "score = competition_scorer(y_test, preds)\n",
        "print('time per prediction:' ,(end-start)/len(X_test))\n",
        "print('The competition score on test data', score)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylpdCoDjQcHA"
      },
      "source": [
        "# Deep Learning approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AgjccCZVy-U"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H24j4wR58Db_"
      },
      "source": [
        "def preprocess_for_tabnet(X,y):\n",
        "  X = X.reset_index()\n",
        "  y = y.reset_index()\n",
        "  y = y['granted_number_of_nights']\n",
        "  return np.array(X), np.array(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WF3Fdnt7yOV4"
      },
      "source": [
        "\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_train, y_train = preprocess_for_tabnet(X_train,y_train)\n",
        "X_val , y_val = preprocess_for_tabnet(X_val ,y_val)\n",
        "clf =  TabNetClassifier(optimizer_fn=torch.optim.Adam,\n",
        "                       optimizer_params=dict(lr=1e-2))\n",
        "clf.device= 'cuda'\n",
        "weights = {0:1,1:10,2:10**2,3:10**3}\n",
        "clf.fit(X_train=X_train, y_train=y_train, ##Train features and train targets\n",
        "                X_valid=X_val, y_valid=y_val, ##Valid features and valid targets\n",
        "                weights=weights,\n",
        "                max_epochs=20,##Maxiµmum number of epochs during training \n",
        "                patience=5, ##Number of consecutive non improving epoch before early stopping\n",
        "                batch_size=1024 ##Training batch size\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSza2VPYb_ox"
      },
      "source": [
        "saved_filepath = clf.save_model('/content/drive/My Drive/Dreamquark_challenge/model_zoo/TabNet_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJHpnCFrV2bV"
      },
      "source": [
        "## Inference on test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fVHXAJmf8mc"
      },
      "source": [
        "requests_test = pd.read_csv('data/requests_test.csv')\n",
        "X_test , y_test = preprocess(requests_test,cat_columns,date_columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULR8ahddfz0U"
      },
      "source": [
        "# Define the test scorer\n",
        "def competition_scorer(y_true, y_pred):\n",
        "    return log_loss(y_true, y_pred, sample_weight=10**y_true)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kO366vdJ_42"
      },
      "source": [
        "# Drop Nan value because otherwise there are memory errors\n",
        "X_test['granted_number_of_nights'] = y_test\n",
        "X_test = X_test.dropna()\n",
        "y_test = X_test['granted_number_of_nights']\n",
        "X_test = X_test.drop(columns = ['granted_number_of_nights'])\n",
        "#preprocess the datasets for TabNet\n",
        "X_test_tab, y_test_tab = preprocess_for_tabnet(X_test,y_test)\n",
        "# retrieve model\n",
        "# Not working\n",
        "\"\"\"\n",
        "PATH = '/content/drive/My Drive/Dreamquark_challenge/model_zoo/TabNet_model.zip'\n",
        "best_model = TabNetClassifier()\n",
        "best_model.load_model(PATH)\n",
        "\"\"\"\n",
        "#run inference\n",
        "start = time.time()\n",
        "preds = clf.predict_proba(X_test_tab)\n",
        "end = time.time()\n",
        "score = competition_scorer(y_test_tab, preds)\n",
        "print('time per prediction:' ,(end-start)/len(X_test))\n",
        "print('The competition score on test data', score)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_VZMoaJq4xT"
      },
      "source": [
        "importance = clf.feature_importances_\n",
        "print(importance)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6duuIMw6aqR"
      },
      "source": [
        "importance.argmax()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_37YWeW98UvA"
      },
      "source": [
        "# Convert to html\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfWnEOoX8YE3"
      },
      "source": [
        "!jupyter nbconvert --to html /content/drive/My\\ Drive/Colab\\ Notebooks/DreamQuark_challenge.ipynb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EU4jPCoc9so3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}